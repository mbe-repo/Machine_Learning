{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import  OneHotEncoder, StandardScaler, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>Date</th>\n",
       "      <th>Weekly_Sales</th>\n",
       "      <th>Holiday_Flag</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Fuel_Price</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Unemployment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>18-02-2011</td>\n",
       "      <td>1572117.54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.61</td>\n",
       "      <td>3.045</td>\n",
       "      <td>214.777523</td>\n",
       "      <td>6.858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store        Date  Weekly_Sales  Holiday_Flag  Temperature  Fuel_Price  \\\n",
       "0    6.0  18-02-2011    1572117.54           NaN        59.61       3.045   \n",
       "\n",
       "          CPI  Unemployment  \n",
       "0  214.777523         6.858  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import Dataset\n",
    "df = pd.read_csv(\"src/Walmart_Store_sales.csv\")\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I - EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II - Linear regression  - Baseline model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Méthodologie : \n",
    "\n",
    "Target => Weekly_Sales\n",
    "\n",
    "Supression de la colonne Date et des lignes ou Weekly_Sales sont Nan\n",
    "Séparation features & target\n",
    "Séparation train and test sets\n",
    "Convertion dy DataFrames en numpy arrays\n",
    "Création un pipeline pour les fonctionnalités numériques & valeurs manquantes\n",
    "Création d'une Pipeline Training\n",
    "Création d'une Pipeline Test\n",
    "Evaluation résulat\n",
    "\n",
    "On observe de l'overfiting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Separating labels from features...\n",
      "Dividing into train and test sets...\n",
      "Convert pandas DataFrames to numpy arrays...\n"
     ]
    }
   ],
   "source": [
    "# sup lignes avec Weekly_Sales Nan\n",
    "df = df.dropna(subset = ['Weekly_Sales'], axis=0)\n",
    "# sup colonne date \n",
    "df.drop(columns=['Date'], inplace=True)\n",
    "\n",
    "\n",
    "# Separate target variable Y from features X\n",
    "print(\"Separating labels from features...\")\n",
    "features_list = ['Store','Holiday_Flag','Temperature','Fuel_Price','CPI','Unemployment']\n",
    "target_variable = \"Weekly_Sales\"\n",
    "\n",
    "\n",
    "dataset = df\n",
    "\n",
    "X = dataset.loc[:,features_list]\n",
    "Y = dataset.loc[:,target_variable]\n",
    "\n",
    "numeric_indices = [2,3,4,5]\n",
    "categorical_indices = [0,1]\n",
    "\n",
    "\n",
    "print(\"Dividing into train and test sets...\")\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Convert pandas DataFrames to numpy arrays before using scikit-learn\n",
    "print(\"Convert pandas DataFrames to numpy arrays...\")\n",
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "Y_train = Y_train.tolist()\n",
    "Y_test = Y_test.tolist()\n",
    "\n",
    "\n",
    "# Créer un pipeline pour les fonctionnalités numériques & valeurs values\n",
    "\n",
    "numeric_features = [2,3,4,5] # Positions of numeric columns in X_train/X_test : Age et Salary\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')), # missing values will be replaced by columns' median\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Créer un pipeline pour les fonctionnalités catégorielles - ici Store - Holiday_Flag & missing values\n",
    "\n",
    "categorical_features = [0,1] # Positions of categorical columns in X_train/X_test\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')), # missing values will be replaced by most frequent value\n",
    "    ('encoder', OneHotEncoder(drop='first')) # first column will be dropped to avoid creating correlations between features\n",
    "    ])\n",
    "\n",
    "# Utilisez ColumnTransformer pour créer un objet préprocesseur qui décrit tous les traitements à effectuer\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II-1 : Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prétraitements on train set: valeurs manquantes, Scale ...\n"
     ]
    }
   ],
   "source": [
    "# Preprocessings (Prétraitements) on train set\n",
    "print(\"Prétraitements on train set: valeurs manquantes, Scale ...\")\n",
    "\n",
    "X_train = preprocessor.fit_transform(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pas de label encoder sur Y car Numerique\n",
    "\n",
    "#labelencoder = LabelEncoder()\n",
    "\n",
    "#print(\"Encoding labels on train set...\")\n",
    "#Y_train = labelencoder.fit_transform(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "print(\"Training model...\")\n",
    "model.fit(X_train, Y_train) # Training is always done on train set !!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions on training set...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 516482.99754619, 1156582.89497736, 1439732.70890009])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predictions on training set\n",
    "print(\"Predictions on training set...\")\n",
    "Y_train_pred = model.predict(X_train)\n",
    "\n",
    "Y_train_pred[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II-2 : Test Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prétraitements on test set...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Preprocessings (Prétraitements) on test set\n",
    "print(\"Prétraitements on test set...\")\n",
    "\n",
    "X_test = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions on test set...\n"
     ]
    }
   ],
   "source": [
    "# Predictions on test set\n",
    "print(\"Predictions on test set...\")\n",
    "Y_test_pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comaraison Y_test et Y_test_pred..\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reality</th>\n",
       "      <th>predi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>757738.76</td>\n",
       "      <td>9.510201e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>418925.47</td>\n",
       "      <td>4.335489e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1532308.78</td>\n",
       "      <td>1.641768e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1466046.67</td>\n",
       "      <td>1.503866e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>268929.03</td>\n",
       "      <td>3.417787e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      reality         predi\n",
       "0   757738.76  9.510201e+05\n",
       "1   418925.47  4.335489e+05\n",
       "2  1532308.78  1.641768e+06\n",
       "3  1466046.67  1.503866e+06\n",
       "4   268929.03  3.417787e+05"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"comaraison Y_test et Y_test_pred..\")\n",
    "\n",
    "compa_Y = pd.DataFrame({'reality':Y_test, 'predi':Y_test_pred})\n",
    "compa_Y[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II-3 : Évaluation des performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score on training set :  0.9617837897020081\n",
      "R2 score on test set :  0.9483868355993639\n"
     ]
    }
   ],
   "source": [
    "# Print R^2 scores\n",
    "print(\"R2 score on training set : \", r2_score(Y_train, Y_train_pred))\n",
    "print(\"R2 score on test set : \", r2_score(Y_test, Y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEA: 111659.25652383358\n",
      "MSE: 21892856146.91282\n",
      "RMSE: 147962.34705800263\n"
     ]
    }
   ],
   "source": [
    "# Evaluation du modéle\n",
    "from sklearn import metrics\n",
    "\n",
    "print(f'MEA: {metrics.mean_absolute_error(Y_test,Y_test_pred)}')\n",
    "print(f'MSE: {metrics.mean_squared_error(Y_test,Y_test_pred)}')\n",
    "print(f'RMSE: {np.sqrt(metrics.mean_squared_error(Y_test,Y_test_pred))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.950044869949645"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.explained_variance_score(Y_test,Y_test_pred)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Overfitting \n",
    "\n",
    "On observe que le modèle d'apprentissage converge trop rapidement vers une solution optimale.\n",
    "modèle trop parfait avec peu de données\n",
    "\n",
    "Pour éviter le surapprentissage en entraînant un modèle de régression régularisé : Ridge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.style.use('seaborn-dark')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II -  Régression linéaire régularisée avec Ridge"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Méthodologie\n",
    "\n",
    "Régression linéaire régularisée :\n",
    "\n",
    " - modèle de régression linéaire Ridge\n",
    " - validation croisée pour estimer comment le score R^2 varie en fonction du choix de l'ensemble de validation\n",
    " - recherche de grille à validation croisée (Grid Search) pour ajuster la valeur de la force de régularisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II -1 import dataset - separation train & test set - preparation des variables numeriques & catégorielles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Separating labels from features...\n",
      "Dividing into train and test sets...\n",
      "Convert pandas DataFrames to numpy arrays...\n"
     ]
    }
   ],
   "source": [
    "#import Dataset\n",
    "df = pd.read_csv(\"src/Walmart_Store_sales.csv\")\n",
    "\n",
    "# sup lignes avec Weekly_Sales Nan\n",
    "df = df.dropna(subset = ['Weekly_Sales'], axis=0)\n",
    "# sup colonne date \n",
    "df.drop(columns=['Date'], inplace=True)\n",
    "\n",
    "\n",
    "# Separate target variable Y from features X\n",
    "print(\"Separating labels from features...\")\n",
    "features_list = ['Store','Holiday_Flag','Temperature','Fuel_Price','CPI','Unemployment']\n",
    "target_variable = \"Weekly_Sales\"\n",
    "\n",
    "\n",
    "dataset = df\n",
    "\n",
    "X = dataset.loc[:,features_list]\n",
    "Y = dataset.loc[:,target_variable]\n",
    "\n",
    "numeric_indices = [2,3,4,5]\n",
    "categorical_indices = [0,1]\n",
    "\n",
    "\n",
    "print(\"Dividing into train and test sets...\")\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Convert pandas DataFrames to numpy arrays before using scikit-learn\n",
    "print(\"Convert pandas DataFrames to numpy arrays...\")\n",
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "Y_train = Y_train.tolist()\n",
    "Y_test = Y_test.tolist()\n",
    "\n",
    "\n",
    "# Créer un pipeline pour les fonctionnalités numériques & valeurs values\n",
    "\n",
    "numeric_features = [2,3,4,5] # Positions of numeric columns in X_train/X_test : Age et Salary\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')), # missing values will be replaced by columns' median\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Créer un pipeline pour les fonctionnalités catégorielles - ici Store - Holiday_Flag & missing values\n",
    "\n",
    "categorical_features = [0,1] # Positions of categorical columns in X_train/X_test\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')), # missing values will be replaced by most frequent value\n",
    "    ('encoder', OneHotEncoder(drop='first')) # first column will be dropped to avoid creating correlations between features\n",
    "    ])\n",
    "\n",
    "# Utilisez ColumnTransformer pour créer un objet préprocesseur qui décrit tous les traitements à effectuer\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II-2 - Training pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prétraitements on train set: valeurs manquantes, Scale ...\n",
      "Training model...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Missing values\n",
    "\n",
    "# Preprocessings (Prétraitements) on train set\n",
    "print(\"Prétraitements on train set: valeurs manquantes, Scale ...\")\n",
    "\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "\n",
    "# Train model\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "print(\"Training model...\")\n",
    "model.fit(X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a- Cross-validated score for a Ridge model (with default value of  λ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-fold cross-validation...\n",
      "The cross-validated R2-score is :  0.8538981764890422\n",
      "The standard deviation is :  0.05594174663336293\n"
     ]
    }
   ],
   "source": [
    "# Perform 3-fold cross-validation to evaluate the generalized R2 score obtained with a Ridge model\n",
    "print(\"3-fold cross-validation...\")\n",
    "regressor = Ridge()\n",
    "scores = cross_val_score(regressor, X_train, Y_train, cv=3)\n",
    "print('The cross-validated R2-score is : ', scores.mean())\n",
    "print('The standard deviation is : ', scores.std())\n",
    "\n",
    "# standart déviation ou écart type : dispersion des données par rapport à la moyenne,\n",
    "#Un écart type proche de zéro indique que les points de données sont proches de la moyenne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b- Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search...\n",
      "\n",
      "Best hyperparameters :  {'alpha': 0.05}\n",
      "Best R2 score :  0.9198185341161347\n"
     ]
    }
   ],
   "source": [
    "# Nous recherchons les meilleurs paramétres avec la librairie de sklearn : Grid Seach\n",
    "# qui permet de sélectionner les meilleurs paramètres parmi les hyperparamètres répertoriés\n",
    "\n",
    "# Perform grid search\n",
    "print(\"Grid search...\")\n",
    "regressor = Ridge()\n",
    "# Grid of values to be tested\n",
    "params = {\n",
    "    'alpha': [0.05, 0.1,0.2,0.5,1.0] # 0 corresponds to no regularization\n",
    "}\n",
    "gridsearch = GridSearchCV(regressor, param_grid = params, cv = 3) # cv : the number of folds to be used for CV\n",
    "gridsearch.fit(X_train, Y_train)\n",
    "print(\"\")\n",
    "print(\"Best hyperparameters : \", gridsearch.best_params_)\n",
    "print(\"Best R2 score : \", gridsearch.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions on training set...\n"
     ]
    }
   ],
   "source": [
    "# Predictions on training set\n",
    "\n",
    "print(\"Predictions on training set...\")\n",
    "Y_train_pred = gridsearch.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II_3 - Test pipeline with Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding categorical features and standardizing numerical features...\n"
     ]
    }
   ],
   "source": [
    "# Missing values\n",
    "X_test[:,numeric_indices] = imputer.transform(X_test[:,numeric_indices])\n",
    "\n",
    "# Encoding categorical features and standardizing numerical features\n",
    "print(\"Encoding categorical features and standardizing numerical features...\")\n",
    "\n",
    "X_test = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 960517.5937938   437720.14965411 1651056.48691219 1470786.3133123\n",
      "  350973.68200533  464325.82888609 1340704.11438538 2023873.6863152\n",
      " 1384557.89290942  411162.26361408  611395.98871814 1511088.0963789\n",
      " 1950992.18491328 1579284.61366373 1945407.78129948 1378334.93421671\n",
      "  570999.73254358 2116354.39761071 2039540.12533715  937007.45653239\n",
      " 1929996.1848169   597652.23987396 1929764.19154327  351939.12588648\n",
      " 2039048.0929218  2000150.25736868 2124703.21616958 1271408.95077164]\n"
     ]
    }
   ],
   "source": [
    "# prediction\n",
    "\n",
    "Y_test_pred = gridsearch.predict(X_test)\n",
    "\n",
    "print(Y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score on training set :  0.9602438002618924\n",
      "R2 score on test set :  0.9402364882097568\n"
     ]
    }
   ],
   "source": [
    "# Print R^2 scores on train/test sets for the Ridge model with optimal value of the regularization strength\n",
    "\n",
    "print(\"R2 score on training set : \", r2_score(Y_train, Y_train_pred))\n",
    "print(\"R2 score on test set : \", r2_score(Y_test, Y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEA of Lasso Regression:: 121065.15217552808\n",
      "MSE: 25350004822.45178\n",
      "RMSE: 159216.8484251958\n"
     ]
    }
   ],
   "source": [
    "# Evaluation du modéle Ridge\n",
    "from sklearn import metrics\n",
    "\n",
    "print(f'MEA of Lasso Regression:: {metrics.mean_absolute_error(Y_test,Y_test_pred)}')\n",
    "print(f'MSE: {metrics.mean_squared_error(Y_test,Y_test_pred)}')\n",
    "print(f'RMSE: {np.sqrt(metrics.mean_squared_error(Y_test,Y_test_pred))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Avec l'utilisation du modèle Ridge, il y a toujours de l'overfiting.\n",
    "Le jeu de donnée n'est pas assez fournit (150 lignes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
